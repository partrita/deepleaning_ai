{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Open Source Models with Hugging Face\n",
    "author:\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo:false\n",
    "\n",
    "from transformers.utils import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Natural Language Processing (NLP)\n",
    "\n",
    "\n",
    "### Build the `chatbot` pipeline using 🤗 Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 5ebf1054-f1c6-4092-a3a1-3ffcc2ca312d\n",
      "user: \n",
      "What is the speed of light?\n",
      "\n",
      "assistant:  Light speeds vary widely depending on the type of light and speed of the object being used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import Conversation\n",
    "\n",
    "# 대화 파이프라인 정의\n",
    "\n",
    "chatbot = pipeline(task=\"conversational\", model=\"facebook/blenderbot-400M-distill\")\n",
    "\n",
    "# 사용자 메시지\n",
    "user_message = \"\"\"\n",
    "What is the speed of light?\n",
    "\"\"\"\n",
    "\n",
    "# 대화 객체 생성 및 사용자 메시지 추가\n",
    "conversation = Conversation(user_message)\n",
    "\n",
    "# 챗봇에 대화 전달 및 응답 받기\n",
    "conversation = chatbot(conversation)\n",
    "\n",
    "# 대화 결과 출력\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can continue the conversation with the chatbot with:\n",
    "```\n",
    "print(chatbot(Conversation(\"What else do you recommend?\")))\n",
    "```\n",
    "- However, the chatbot may provide an unrelated response because it does not have memory of any prior conversations.\n",
    "\n",
    "- To include prior conversations in the LLM's context, you can add a 'message' to include the previous chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 5ebf1054-f1c6-4092-a3a1-3ffcc2ca312d\n",
      "user: \n",
      "What is the speed of light?\n",
      "\n",
      "assistant:  Light speeds vary widely depending on the type of light and speed of the object being used.\n",
      "user: \n",
      "        Do you think that I think you have consciousness?\n",
      "        \n",
      "assistant:  I don't think I have any consciousness, but I do believe that I have a good sense of self-awareness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.add_message(\n",
    "    {\n",
    "        \"role\": \"user\",  # 메시지의 역할을 \"user\"로 설정합니다. (사용자 메시지)\n",
    "        \"content\": \"\"\"\n",
    "        Do you think that I think you have consciousness?\n",
    "        \"\"\",\n",
    "    }\n",
    ")\n",
    "\n",
    "conversation = chatbot(conversation)  # 챗봇에게 대화를 전달하고 응답을 받습니다.\n",
    "\n",
    "print(conversation)  # 대화 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Translation and Summarization\n",
    "\n",
    "### Build the `translation` pipeline using 🤗 Transformers Library\n",
    "\n",
    "NLLB: No Language Left Behind: ['nllb-200-distilled-600M'](https://huggingface.co/facebook/nllb-200-distilled-600M).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0785482572d44b68d9fd880bead68ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322474a5c0f245dd8447da26e9dac16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bd6e3e266d46ea8c672400ed05e6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c47d895454441b4be54d4705b78ea5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce5422ebd4c4c65a26c7a999b11ed0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd20f9d17024b91b25ffd87285bd476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f92e36d6034c2b95b6ebd1ca8c900d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Mon chiot est adorable, ton chaton est mignon, son panda est ami, sa lamme est attentive, nous avons tous de beaux animaux de compagnie.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "translator = pipeline(\n",
    "    task=\"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\"\n",
    "\n",
    "text_translated = translator(text, src_lang=\"eng_Latn\", tgt_lang=\"fra_Latn\")\n",
    "\n",
    "text_translated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose other languages, you can find the other language codes on the page: [Languages in FLORES-200](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200)\n",
    "\n",
    "For example:\n",
    "- Afrikaans: afr_Latn\n",
    "- Chinese: zho_Hans\n",
    "- Egyptian Arabic: arz_Arab\n",
    "- French: fra_Latn\n",
    "- German: deu_Latn\n",
    "- Greek: ell_Grek\n",
    "- Hindi: hin_Deva\n",
    "- Indonesian: ind_Latn\n",
    "- Italian: ita_Latn\n",
    "- Japanese: jpn_Jpan\n",
    "- Korean: kor_Hang\n",
    "- Persian: pes_Arab\n",
    "- Portuguese: por_Latn\n",
    "- Russian: rus_Cyrl\n",
    "- Spanish: spa_Latn\n",
    "- Swahili: swh_Latn\n",
    "- Thai: tha_Thai\n",
    "- Turkish: tur_Latn\n",
    "- Vietnamese: vie_Latn\n",
    "- Zulu: zul_Latn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': '내 강아지는 사랑스럽고, 당신의 새끼 고양이는 귀여운데, 그녀의 팬다는 친절하고, 그의 라마는 신중합니다. 우리 모두는 좋은 애완동물들을 가지고 있습니다.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\"\n",
    "\n",
    "text_translated = translator(text, src_lang=\"eng_Latn\", tgt_lang=\"kor_Hang\")\n",
    "\n",
    "text_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up some memory before continuing\n",
    "import gc\n",
    "\n",
    "del translator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the `summarization` pipeline using 🤗 Transformers Library\n",
    "\n",
    "Model info: ['bart-large-cnn'](https://huggingface.co/facebook/bart-large-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c4a1c56d-0589-48cd-9717-f6c33a86fa3b/dataScience/deepleaning_ai/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89397f82b0364566b70a18d88931ff48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fed0545b94e41af832a05bd2ecc02ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f378c37c4efe4857bfeaef949c99d3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6956dff88840fb906dd718b0cf26e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c65e421919f4516acd8955836e8bae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43371bb381924015a398dea0427b5d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018. The City of Paris is the centre and seat of the government of the region and province of Île-de-France.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\n",
    "    task=\"summarization\", model=\"facebook/bart-large-cnn\", torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "text = \"\"\"Paris is the capital and most populous city of France, with\n",
    "          an estimated population of 2,175,601 residents as of 2018,\n",
    "          in an area of more than 105 square kilometres (41 square\n",
    "          miles). The City of Paris is the centre and seat of\n",
    "          government of the region and province of Île-de-France, or\n",
    "          Paris Region, which has an estimated population of\n",
    "          12,174,880, or about 18 percent of the population of France\n",
    "          as of 2017.\"\"\"\n",
    "\n",
    "\n",
    "summary = summarizer(text, min_length=10, max_length=100)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free up some memory before continuing\n",
    "import gc\n",
    "\n",
    "del summarizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Sentence Embeddings\n",
    "\n",
    "### Build the `sentence embedding` pipeline using 🤗 Transformers Library\n",
    "\n",
    "More info on [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad7d84d891546888dd49e830ae9b90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1392,  0.0030,  0.0470,  ...,  0.0641, -0.0163,  0.0636],\n",
       "        [ 0.0227, -0.0014, -0.0056,  ..., -0.0225,  0.0846, -0.0283],\n",
       "        [-0.1043, -0.0628,  0.0093,  ...,  0.0020,  0.0653, -0.0150]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences1 = [\n",
    "    \"The cat sits outside\",\n",
    "    \"A man is playing guitar\",\n",
    "    \"The movies are awesome\",\n",
    "]\n",
    "\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0163, -0.0700,  0.0384,  ...,  0.0447,  0.0254, -0.0023],\n",
      "        [ 0.0054, -0.0920,  0.0140,  ...,  0.0167, -0.0086, -0.0424],\n",
      "        [-0.0842, -0.0592, -0.0010,  ..., -0.0157,  0.0764,  0.0389]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"A woman watches TV\",\n",
    "    \"The new movie is so great\",\n",
    "]\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "print(embeddings2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the cosine similarity between two sentences as a measure of how similar they are to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2838,  0.1310, -0.0029],\n",
      "        [ 0.2277, -0.0327, -0.0136],\n",
      "        [-0.0124, -0.0465,  0.6571]], device='cuda:0')\n",
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The movies are awesome \t\t The new movie is so great \t\t Score: 0.6571\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "print(cosine_scores)\n",
    "for i in range(len(sentences1)):\n",
    "    print(\n",
    "        \"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "            sentences1[i], sentences2[i], cosine_scores[i][i]\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

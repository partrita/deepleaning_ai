{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Open Source Models with Hugging Face\n",
    "author:\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo:false\n",
    "\n",
    "from transformers.utils import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어 처리 (NLP)\n",
    "\n",
    "\n",
    "## 🤗 Transformers 라이브러리를 사용하여 `챗봇` 파이프라인 구축하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c4a1c56d-0589-48cd-9717-f6c33a86fa3b/dataScience/deepleaning_ai/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/mnt/c4a1c56d-0589-48cd-9717-f6c33a86fa3b/dataScience/deepleaning_ai/.venv/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: aeaa0179-f9dc-4f00-ac42-b85b4e4092ea\n",
      "user: \n",
      "What is the speed of light?\n",
      "\n",
      "assistant:  Light speeds vary widely depending on the type of light and speed of the object being used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import Conversation\n",
    "\n",
    "# 대화 파이프라인 정의\n",
    "\n",
    "chatbot = pipeline(task=\"conversational\", model=\"facebook/blenderbot-400M-distill\")\n",
    "\n",
    "# 사용자 메시지\n",
    "user_message = \"\"\"\n",
    "What is the speed of light?\n",
    "\"\"\"\n",
    "\n",
    "# 대화 객체 생성 및 사용자 메시지 추가\n",
    "conversation = Conversation(user_message)\n",
    "\n",
    "# 챗봇에 대화 전달 및 응답 받기\n",
    "conversation = chatbot(conversation)\n",
    "\n",
    "# 대화 결과 출력\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 챗봇과의 대화를 계속해 나갈 수 있지만 챗봇은 이전 대화에 대한 기억이 없기 때문에 관련 없는 응답을 제공합니다.\n",
    "\n",
    "```python\n",
    "print(chatbot(Conversation(\"다른 추천 사항이 있나요?\")))\n",
    "```\n",
    "\n",
    "만약 이전 대화 내용을 포함하려면 아래와 같이 이전 채팅 기록을 포함하는 '메시지'를 추가하면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: aeaa0179-f9dc-4f00-ac42-b85b4e4092ea\n",
      "user: \n",
      "What is the speed of light?\n",
      "\n",
      "assistant:  Light speeds vary widely depending on the type of light and speed of the object being used.\n",
      "user: \n",
      "        Do you think that I think you have consciousness?\n",
      "        \n",
      "assistant:  I don't think I have any consciousness, but I do believe that I have a good sense of self-awareness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.add_message(\n",
    "    {\n",
    "        \"role\": \"user\",  # 메시지의 역할을 \"user\"로 설정합니다. (사용자 메시지)\n",
    "        \"content\": \"\"\"\n",
    "        Do you think that I think you have consciousness?\n",
    "        \"\"\",\n",
    "    }\n",
    ")\n",
    "\n",
    "conversation = chatbot(conversation)  # 챗봇에게 대화를 전달하고 응답을 받습니다.\n",
    "\n",
    "print(conversation)  # 대화 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 번역 및 요약\n",
    "\n",
    "## 🤗 Transformers 라이브러리를 사용하여 `번역` 파이프라인 구축하기\n",
    "\n",
    "NLLB: 다양한 언어를 지원하는 번역 모델: ['nllb-200-distilled-600M'](https://huggingface.co/facebook/nllb-200-distilled-600M).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Mon chiot est adorable, ton chaton est mignon, son panda est ami, sa lamme est attentive, nous avons tous de beaux animaux de compagnie.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# 번역 파이프라인 생성\n",
    "translator = pipeline(\n",
    "    task=\"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",  # 사용할 모델:\n",
    "    torch_dtype=torch.bfloat16,  # 모델의 데이터 유형: bfloat16\n",
    ")\n",
    "\n",
    "# 번역할 텍스트 정의\n",
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\"\n",
    "\n",
    "# 텍스트 번역\n",
    "translated_text = translator(\n",
    "    text, src_lang=\"eng_Latn\", tgt_lang=\"fra_Latn\"\n",
    ")  # 영어에서 프랑스어로 번역\n",
    "\n",
    "# 번역 결과 출력\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 언어를 선택하려면 다음 페이지에서 다른 언어 코드를 찾을 수 있습니다. [FLORES-200의 언어](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200)\n",
    "\n",
    "지원되는 언어는 아래와 같습니다.\n",
    "- Afrikaans: afr_Latn\n",
    "- Chinese: zho_Hans\n",
    "- Egyptian Arabic: arz_Arab\n",
    "- French: fra_Latn\n",
    "- German: deu_Latn\n",
    "- Greek: ell_Grek\n",
    "- Hindi: hin_Deva\n",
    "- Indonesian: ind_Latn\n",
    "- Italian: ita_Latn\n",
    "- Japanese: jpn_Jpan\n",
    "- Korean: kor_Hang\n",
    "- Persian: pes_Arab\n",
    "- Portuguese: por_Latn\n",
    "- Russian: rus_Cyrl\n",
    "- Spanish: spa_Latn\n",
    "- Swahili: swh_Latn\n",
    "- Thai: tha_Thai\n",
    "- Turkish: tur_Latn\n",
    "- Vietnamese: vie_Latn\n",
    "- Zulu: zul_Latn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': '내 강아지는 사랑스럽고, 당신의 새끼 고양이는 귀여운데, 그녀의 팬다는 친절하고, 그의 라마는 신중합니다. 우리 모두는 좋은 애완동물들을 가지고 있습니다.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\"\n",
    "\n",
    "text_translated = translator(text, src_lang=\"eng_Latn\", tgt_lang=\"kor_Hang\")\n",
    "\n",
    "text_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계속하기 전에 메모리를 일부 해제합니다.\n",
    "import gc\n",
    "\n",
    "del translator  # 번역기 객체를 삭제합니다.\n",
    "gc.collect()  # 가비지 컬렉션을 수행하여 사용하지 않는 메모리를 회수합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤗 Transformers 라이브러리를 사용하여 `요약` 파이프라인 구축하기\n",
    "\n",
    "모델 정보: ['bart-large-cnn'](https://huggingface.co/facebook/bart-large-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018. The City of Paris is the centre and seat of the government of the region and province of Île-de-France.'}]\n"
     ]
    }
   ],
   "source": [
    "# 요약 파이프라인 생성\n",
    "summarizer = pipeline(\n",
    "    task=\"summarization\", model=\"facebook/bart-large-cnn\", torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# 요약할 텍스트 정의\n",
    "text = \"\"\"Paris is the capital and most populous city of France, with\n",
    "          an estimated population of 2,175,601 residents as of 2018,\n",
    "          in an area of more than 105 square kilometres (41 square\n",
    "          miles). The City of Paris is the centre and seat of\n",
    "          government of the region and province of Île-de-France, or\n",
    "          Paris Region, which has an estimated population of\n",
    "          12,174,880, or about 18 percent of the population of France\n",
    "          as of 2017.\"\"\"\n",
    "\n",
    "# 텍스트 요약\n",
    "summary = summarizer(text, min_length=10, max_length=100)\n",
    "# 요약 결과 출력\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del summarizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장 임베딩\n",
    "\n",
    "## 🤗 Transformers 라이브러리를 사용하여 `문장 임베딩` 파이프라인 구축하기\n",
    "\n",
    "[all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)에 대한 추가 정보.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1392,  0.0030,  0.0470,  ...,  0.0641, -0.0163,  0.0636],\n",
       "        [ 0.0227, -0.0014, -0.0056,  ..., -0.0225,  0.0846, -0.0283],\n",
       "        [-0.1043, -0.0628,  0.0093,  ...,  0.0020,  0.0653, -0.0150]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences1 = [\n",
    "    \"The cat sits outside\",\n",
    "    \"A man is playing guitar\",\n",
    "    \"The movies are awesome\",\n",
    "]\n",
    "\n",
    "# 문장 목록을 임베딩 벡터로 변환 (텐서로 변환)\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "# 생성된 임베딩 벡터 출력\n",
    "# embeddings1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0163, -0.0700,  0.0384,  ...,  0.0447,  0.0254, -0.0023],\n",
      "        [ 0.0054, -0.0920,  0.0140,  ...,  0.0167, -0.0086, -0.0424],\n",
      "        [-0.0842, -0.0592, -0.0010,  ..., -0.0157,  0.0764,  0.0389]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"A woman watches TV\",\n",
    "    \"The new movie is so great\",\n",
    "]\n",
    "\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "print(embeddings2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 문장 사이의 코사인 유사도를 계산하여 두 문장이 서로 얼마나 유사한지를 측정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside          The dog plays in the garden        0.2838\n",
      "A man is playing guitar       A woman watches TV                 -0.0327\n",
      "The movies are awesome        The new movie is so great          0.6571\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "for i in range(len(sentences1)):\n",
    "    print(f\"{sentences1[i]:<30}{sentences2[i]:<35}{cosine_scores[i][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

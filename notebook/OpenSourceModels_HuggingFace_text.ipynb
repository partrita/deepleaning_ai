{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Open Source Models with Hugging Face\n",
    "author:\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo:false\n",
    "\n",
    "from transformers.utils import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Natural Language Processing (NLP)\n",
    "\n",
    "\n",
    "### Build the `chatbot` pipeline using ğŸ¤— Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 5ebf1054-f1c6-4092-a3a1-3ffcc2ca312d\n",
      "user: \n",
      "What is the speed of light?\n",
      "\n",
      "assistant:  Light speeds vary widely depending on the type of light and speed of the object being used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import Conversation\n",
    "\n",
    "# ëŒ€í™” íŒŒì´í”„ë¼ì¸ ì •ì˜\n",
    "\n",
    "chatbot = pipeline(task=\"conversational\", model=\"facebook/blenderbot-400M-distill\")\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€\n",
    "user_message = \"\"\"\n",
    "What is the speed of light?\n",
    "\"\"\"\n",
    "\n",
    "# ëŒ€í™” ê°ì²´ ìƒì„± ë° ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "conversation = Conversation(user_message)\n",
    "\n",
    "# ì±—ë´‡ì— ëŒ€í™” ì „ë‹¬ ë° ì‘ë‹µ ë°›ê¸°\n",
    "conversation = chatbot(conversation)\n",
    "\n",
    "# ëŒ€í™” ê²°ê³¼ ì¶œë ¥\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can continue the conversation with the chatbot with:\n",
    "```\n",
    "print(chatbot(Conversation(\"What else do you recommend?\")))\n",
    "```\n",
    "- However, the chatbot may provide an unrelated response because it does not have memory of any prior conversations.\n",
    "\n",
    "- To include prior conversations in the LLM's context, you can add a 'message' to include the previous chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 5ebf1054-f1c6-4092-a3a1-3ffcc2ca312d\n",
      "user: \n",
      "What is the speed of light?\n",
      "\n",
      "assistant:  Light speeds vary widely depending on the type of light and speed of the object being used.\n",
      "user: \n",
      "        Do you think that I think you have consciousness?\n",
      "        \n",
      "assistant:  I don't think I have any consciousness, but I do believe that I have a good sense of self-awareness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.add_message(\n",
    "    {\n",
    "        \"role\": \"user\",  # ë©”ì‹œì§€ì˜ ì—­í• ì„ \"user\"ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. (ì‚¬ìš©ì ë©”ì‹œì§€)\n",
    "        \"content\": \"\"\"\n",
    "        Do you think that I think you have consciousness?\n",
    "        \"\"\",\n",
    "    }\n",
    ")\n",
    "\n",
    "conversation = chatbot(conversation)  # ì±—ë´‡ì—ê²Œ ëŒ€í™”ë¥¼ ì „ë‹¬í•˜ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.\n",
    "\n",
    "print(conversation)  # ëŒ€í™” ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Translation and Summarization\n",
    "\n",
    "### Build the `translation` pipeline using ğŸ¤— Transformers Library\n",
    "\n",
    "NLLB: No Language Left Behind: ['nllb-200-distilled-600M'](https://huggingface.co/facebook/nllb-200-distilled-600M).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0785482572d44b68d9fd880bead68ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322474a5c0f245dd8447da26e9dac16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bd6e3e266d46ea8c672400ed05e6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c47d895454441b4be54d4705b78ea5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce5422ebd4c4c65a26c7a999b11ed0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd20f9d17024b91b25ffd87285bd476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f92e36d6034c2b95b6ebd1ca8c900d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Mon chiot est adorable, ton chaton est mignon, son panda est ami, sa lamme est attentive, nous avons tous de beaux animaux de compagnie.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "translator = pipeline(\n",
    "    task=\"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\"\n",
    "\n",
    "text_translated = translator(text, src_lang=\"eng_Latn\", tgt_lang=\"fra_Latn\")\n",
    "\n",
    "text_translated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose other languages, you can find the other language codes on the page: [Languages in FLORES-200](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200)\n",
    "\n",
    "For example:\n",
    "- Afrikaans: afr_Latn\n",
    "- Chinese: zho_Hans\n",
    "- Egyptian Arabic: arz_Arab\n",
    "- French: fra_Latn\n",
    "- German: deu_Latn\n",
    "- Greek: ell_Grek\n",
    "- Hindi: hin_Deva\n",
    "- Indonesian: ind_Latn\n",
    "- Italian: ita_Latn\n",
    "- Japanese: jpn_Jpan\n",
    "- Korean: kor_Hang\n",
    "- Persian: pes_Arab\n",
    "- Portuguese: por_Latn\n",
    "- Russian: rus_Cyrl\n",
    "- Spanish: spa_Latn\n",
    "- Swahili: swh_Latn\n",
    "- Thai: tha_Thai\n",
    "- Turkish: tur_Latn\n",
    "- Vietnamese: vie_Latn\n",
    "- Zulu: zul_Latn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'ë‚´ ê°•ì•„ì§€ëŠ” ì‚¬ë‘ìŠ¤ëŸ½ê³ , ë‹¹ì‹ ì˜ ìƒˆë¼ ê³ ì–‘ì´ëŠ” ê·€ì—¬ìš´ë°, ê·¸ë…€ì˜ íŒ¬ë‹¤ëŠ” ì¹œì ˆí•˜ê³ , ê·¸ì˜ ë¼ë§ˆëŠ” ì‹ ì¤‘í•©ë‹ˆë‹¤. ìš°ë¦¬ ëª¨ë‘ëŠ” ì¢‹ì€ ì• ì™„ë™ë¬¼ë“¤ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\"\n",
    "\n",
    "text_translated = translator(text, src_lang=\"eng_Latn\", tgt_lang=\"kor_Hang\")\n",
    "\n",
    "text_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up some memory before continuing\n",
    "import gc\n",
    "\n",
    "del translator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the `summarization` pipeline using ğŸ¤— Transformers Library\n",
    "\n",
    "Model info: ['bart-large-cnn'](https://huggingface.co/facebook/bart-large-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c4a1c56d-0589-48cd-9717-f6c33a86fa3b/dataScience/deepleaning_ai/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89397f82b0364566b70a18d88931ff48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fed0545b94e41af832a05bd2ecc02ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f378c37c4efe4857bfeaef949c99d3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6956dff88840fb906dd718b0cf26e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c65e421919f4516acd8955836e8bae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43371bb381924015a398dea0427b5d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018. The City of Paris is the centre and seat of the government of the region and province of Ãle-de-France.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\n",
    "    task=\"summarization\", model=\"facebook/bart-large-cnn\", torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "text = \"\"\"Paris is the capital and most populous city of France, with\n",
    "          an estimated population of 2,175,601 residents as of 2018,\n",
    "          in an area of more than 105 square kilometres (41 square\n",
    "          miles). The City of Paris is the centre and seat of\n",
    "          government of the region and province of Ãle-de-France, or\n",
    "          Paris Region, which has an estimated population of\n",
    "          12,174,880, or about 18 percent of the population of France\n",
    "          as of 2017.\"\"\"\n",
    "\n",
    "\n",
    "summary = summarizer(text, min_length=10, max_length=100)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free up some memory before continuing\n",
    "import gc\n",
    "\n",
    "del summarizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Sentence Embeddings\n",
    "\n",
    "### Build the `sentence embedding` pipeline using ğŸ¤— Transformers Library\n",
    "\n",
    "More info on [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad7d84d891546888dd49e830ae9b90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1392,  0.0030,  0.0470,  ...,  0.0641, -0.0163,  0.0636],\n",
       "        [ 0.0227, -0.0014, -0.0056,  ..., -0.0225,  0.0846, -0.0283],\n",
       "        [-0.1043, -0.0628,  0.0093,  ...,  0.0020,  0.0653, -0.0150]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences1 = [\n",
    "    \"The cat sits outside\",\n",
    "    \"A man is playing guitar\",\n",
    "    \"The movies are awesome\",\n",
    "]\n",
    "\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0163, -0.0700,  0.0384,  ...,  0.0447,  0.0254, -0.0023],\n",
      "        [ 0.0054, -0.0920,  0.0140,  ...,  0.0167, -0.0086, -0.0424],\n",
      "        [-0.0842, -0.0592, -0.0010,  ..., -0.0157,  0.0764,  0.0389]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"A woman watches TV\",\n",
    "    \"The new movie is so great\",\n",
    "]\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "print(embeddings2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the cosine similarity between two sentences as a measure of how similar they are to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2838,  0.1310, -0.0029],\n",
      "        [ 0.2277, -0.0327, -0.0136],\n",
      "        [-0.0124, -0.0465,  0.6571]], device='cuda:0')\n",
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The movies are awesome \t\t The new movie is so great \t\t Score: 0.6571\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "print(cosine_scores)\n",
    "for i in range(len(sentences1)):\n",
    "    print(\n",
    "        \"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "            sentences1[i], sentences2[i], cosine_scores[i][i]\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
